{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Coursera\n",
    "## Анализ данных: финальный проект\n",
    "### Жёлтое такси в Нью-Йорке\n",
    "#### Михалев Антон"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# неделя 07: Оформление проекта"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# версия для запуска на kaggle\n",
    "* это единственный способ, которым удалось запустить интерактив на моем локальном компьютере\n",
    "* копия ноутбука - на kaggle https://www.kaggle.com/antonmikhalev/coursera-taxi-week-07, там точно работает, нужно сделать \"COPY AND EDIT\" и перезапустить ноутбук\n",
    "* либо можно попробовать запускать локальную копию на своем компьютере"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## интерактивное демо, содержащее:\n",
    "* карты с визуализацией реального и прогнозируемого спроса на такси в выбираемый пользователем момент времени\n",
    "* временной ряд фактического и прогнозируемого спроса на такси в выбираемой области.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### для визуализации - взяты материалы по ссылке:\n",
    "* https://blog.dominodatalab.com/interactive-dashboards-in-jupyter/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ограничения:\n",
    "* показываются данные - только за июнь 2016 (реальные/прогнозные)\n",
    "* показываются только регионы, отобранные на предыдущих занятиях (102 шт)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## исходные данные:\n",
    "* страница со ссылками: https://www1.nyc.gov/site/tlc/about/tlc-trip-record-data.page\n",
    "* отдельные файлы:\n",
    "    * за период с 2009-01 до 2019-06\n",
    "        * https://s3.amazonaws.com/nyc-tlc/trip+data/yellow_tripdata_2009-01.csv\n",
    "        * ...\n",
    "        * https://s3.amazonaws.com/nyc-tlc/trip+data/yellow_tripdata_2019-06.csv\n",
    "    \n",
    "    * за период с 2019-07 до 2020-12\n",
    "        * https://nyc-tlc.s3.amazonaws.com/trip+data/yellow_tripdata_2019-07.csv\n",
    "        * ...\n",
    "        * https://nyc-tlc.s3.amazonaws.com/trip+data/yellow_tripdata_2020-12.csv\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* ссылка на kaggle - https://inclass.kaggle.com/c/yellowtaxi."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install pandas\n",
    "# !pip install fsspec\n",
    "# !pip install matplotlib\n",
    "# !pip install scipy\n",
    "# !pip install basemap\n",
    "# !pip install folium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from pandas.tseries.holiday import USFederalHolidayCalendar\n",
    "\n",
    "from scipy import stats\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import itertools as it\n",
    "\n",
    "import datetime as dt\n",
    "\n",
    "import warnings\n",
    "\n",
    "import gc\n",
    "\n",
    "%pylab inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ipywidgets import widgets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import folium\n",
    "from folium.plugins import HeatMap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from ipywidgets import *\n",
    "\n",
    "# def f(x):\n",
    "#     print(x)\n",
    "    \n",
    "# widgets.interact(f, x=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from ipywidgets import *\n",
    "# from IPython.display import display\n",
    "# from IPython.html import widgets\n",
    "\n",
    "# text = widgets.Text(description=\"Domain to ping\", width=200)\n",
    "# display(text);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# widgets.Dropdown(\n",
    "#     options=['1', '2', '3'],\n",
    "#     value='2',\n",
    "#     description='Number:',\n",
    "#     disabled=False,\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# вспомогательные функции\n",
    "собраны в начало ноутбука, чтобы было удобнее перезапускать по частям"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# тестовые отладочные параметры\n",
    "\n",
    "__nrows_full = None\n",
    "__nrows_10 = 10_000\n",
    "\n",
    "# __nrows_week_01 = __nrows_full\n",
    "# __nrows_week_01 = __nrows_10\n",
    "\n",
    "__nrows_pipeline = __nrows_full\n",
    "# __nrows_pipeline = __nrows_10\n",
    "\n",
    "# __need_pipeline=True\n",
    "__need_pipeline=False\n",
    "\n",
    "# __need_pipeline_2016_05=True\n",
    "__need_pipeline_2016_05=False\n",
    "# __need_pipeline_2016_06=True\n",
    "__need_pipeline_2016_06=False\n",
    "\n",
    "# __need_save_year=True\n",
    "__need_save_year=False\n",
    "\n",
    "__need_load_year=True\n",
    "# __need_load_year=False\n",
    "\n",
    "__need_load_more_5=True\n",
    "# __need_load_more_5=False\n",
    "\n",
    "# __need_save_region=True\n",
    "# __need_save_region=False\n",
    "\n",
    "# __need_load_region=True\n",
    "# __need_load_region=False\n",
    "\n",
    "# __nrows_sarimax_fit = __nrows_full\n",
    "# __nrows_sarimax_fit = 1_000\n",
    "\n",
    "# __nrows_sarimax_grid = __nrows_full\n",
    "__nrows_sarimax_grid = 1_000\n",
    "\n",
    "# __use_1_model = True\n",
    "__use_1_model = False\n",
    "\n",
    "__model_rows = __nrows_full\n",
    "# __model_rows = 5_000\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_pred = 6\n",
    "\n",
    "K = 23\n",
    "K_d = 4\n",
    "stat_len = 24\n",
    "sum_list = [12, 24, 24*7, 24*7*4] # полдня, сутки, неделю, месяц\n",
    "near_len = 24\n",
    "\n",
    "skip_begin = K_d * 24\n",
    "skip_end = K\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_york_coords = {\n",
    "    'west': -74.25559, \n",
    "    'east': -73.70001, \n",
    "    'north': 40.91553, \n",
    "    'south': 40.49612, \n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "empire_state_building_region = 1231"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# получаем список имен файлов по списку годов/месяцев\n",
    "\n",
    "s3_amazonaws_com_nyc_tlc_link = 'https://s3.amazonaws.com/nyc-tlc/trip+data/'\n",
    "nyc_tlc_s3_amazonaws_com_link = 'https://nyc-tlc.s3.amazonaws.com/trip+data/'\n",
    "local_folder = '../data/'\n",
    "\n",
    "def get_names(use_local, dates):\n",
    "    result = []\n",
    "    for year, month in dates:\n",
    "        if use_local:\n",
    "            result.append(f'{local_folder}yellow_tripdata_{year}-{month:02}.csv')\n",
    "        else:\n",
    "            result.append(f'{nyc_tlc_s3_amazonaws_com_link}yellow_tripdata_{year}-{month:02}.csv')\n",
    "    \n",
    "    return result\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# загружаем весь список файлов в один длинный дата-фрейм\n",
    "\n",
    "def load_data(names, nrows=None, columns=[]):\n",
    "    result = None\n",
    "    \n",
    "    for i, name in enumerate(names):\n",
    "        print(f'{i+1}/{len(names)}:{name}')\n",
    "        \n",
    "        load_df = pd.read_csv(name, parse_dates=['tpep_pickup_datetime', 'tpep_dropoff_datetime'], nrows=nrows)        \n",
    "        load_df = drop_columns_except(load_df, columns=columns)\n",
    "        \n",
    "        if result is None:\n",
    "            result = load_df\n",
    "        else:\n",
    "            result = pd.concat([\n",
    "                result, \n",
    "                load_df\n",
    "            ])\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# удаляем колонки, за исключением указанных\n",
    "\n",
    "def drop_columns_except(data, columns):\n",
    "    data.drop(columns=list(set(data.columns) - set(columns)), inplace=True)\n",
    "    return data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# чистим данные\n",
    "\n",
    "def clear_data(data):\n",
    "    data.drop(data\n",
    "              [\n",
    "                (data['tpep_dropoff_datetime'] == data['tpep_pickup_datetime']) |    \n",
    "                (data['passenger_count'] <= 0) |    \n",
    "                (data['trip_distance'] <= 0) |    \n",
    "                (data['pickup_longitude'] < new_york_coords['west']) | (data['pickup_longitude'] > new_york_coords['east']) |\n",
    "                (data['pickup_latitude'] < new_york_coords['south']) | (data['pickup_latitude'] > new_york_coords['north'])\n",
    "              ].index, inplace=True)\n",
    "    \n",
    "    return data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# округляем время до часов\n",
    "\n",
    "def round_time(data):\n",
    "    data['tpep_pickup_datetime'] = data['tpep_pickup_datetime'].dt.floor(\"H\")\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# считаем статистику по регионам\n",
    "\n",
    "def calc_bins(data, bins):\n",
    "    bins_result = stats.binned_statistic_2d(data['pickup_longitude'], data['pickup_latitude'], \n",
    "                                        None, \n",
    "                                        statistic='count', \n",
    "                                        bins=bins,\n",
    "                                        expand_binnumbers=True,\n",
    "                                       )\n",
    "    data['region'] = (bins_result.binnumber[0] - 1) * 50 + bins_result.binnumber[1]\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# считаем групповую статистику по регионам и часам\n",
    "\n",
    "def calc_aggregated(data):\n",
    "    result_aggregated = data.groupby([\"tpep_pickup_datetime\", \"region\"]).size().to_frame(name='count')\n",
    "    result_aggregated['passenger_count'] = data.groupby([\"tpep_pickup_datetime\", \"region\"])['passenger_count'].sum()\n",
    "    \n",
    "    return result_aggregated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# расширяем групповую статистику до полного набора всех возможных значений\n",
    "\n",
    "def expand_aggregated(data_aggregated, datetime_all, region_all):\n",
    "    all_product = pd.DataFrame([[x0, y0] for x0 in datetime_all for y0 in region_all], columns=['tpep_pickup_datetime', 'region'])\n",
    "    all_product.set_index(['tpep_pickup_datetime', 'region'], inplace=True)\n",
    "    all_product['count_dummy'] = None\n",
    "    \n",
    "    data_aggregated_all = all_product.join(data_aggregated)\n",
    "    \n",
    "    data_aggregated_all.drop(columns=['count_dummy'], inplace=True)\n",
    "    \n",
    "    data_aggregated_all.fillna(0, inplace=True)\n",
    "    \n",
    "    data_aggregated_all.reset_index(inplace=True)\n",
    "\n",
    "    return data_aggregated_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# полный цикл обработки для заданного списка файлов\n",
    "\n",
    "def full_pipeline(names, nrows, bins, data_regions):\n",
    "    print('(-/6) pipeline begin...')\n",
    "\n",
    "    result = load_data(names, nrows=nrows, columns=['tpep_pickup_datetime', 'tpep_dropoff_datetime', 'pickup_longitude', 'pickup_latitude', 'passenger_count', 'trip_distance'])\n",
    "    print('(1/6) load_data end...')\n",
    "\n",
    "    result = clear_data(result)\n",
    "    result = drop_columns_except(result, ['tpep_pickup_datetime', 'pickup_longitude', 'pickup_latitude', 'passenger_count'])\n",
    "    print('(2/6) clear_data end...')\n",
    "    \n",
    "    result = round_time(result)\n",
    "    print('(3/6) round_time end...')\n",
    "    \n",
    "    result = calc_bins(result, bins=bins)\n",
    "    result = drop_columns_except(result, ['tpep_pickup_datetime', 'region', 'passenger_count'])\n",
    "    print('(4/6) calc_bins end...')\n",
    "    \n",
    "    result_aggregated = calc_aggregated(result)\n",
    "    print('(5/6) calc_aggregated end...')\n",
    "        \n",
    "    result_aggregated_expanded = expand_aggregated(result_aggregated, result_aggregated.index.unique(level='tpep_pickup_datetime'), data_regions['region'].unique())\n",
    "    result_aggregated_expanded = drop_columns_except(result_aggregated_expanded, ['tpep_pickup_datetime', 'region', 'count', 'passenger_count'])\n",
    "    print('(6/6) expand_aggregated end...')\n",
    "    \n",
    "    print('(-/-) pipeline end...')\n",
    "    return result_aggregated_expanded\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_date_columns(df, column_prefix=None):\n",
    "    date_columns = []\n",
    "    \n",
    "    column_name = 'date_year'\n",
    "    if column_prefix is not None:\n",
    "        column_name = (column_prefix, column_name)        \n",
    "    df[column_name] = df.index.year\n",
    "    date_columns.append(column_name)\n",
    "\n",
    "    column_name = 'date_month'\n",
    "    if column_prefix is not None:\n",
    "        column_name = (column_prefix, column_name)        \n",
    "    df[column_name] = df.index.month\n",
    "    date_columns.append(column_name)\n",
    "\n",
    "    column_name = 'date_day'\n",
    "    if column_prefix is not None:\n",
    "        column_name = (column_prefix, column_name)        \n",
    "    df[column_name] = df.index.day\n",
    "    date_columns.append(column_name)\n",
    "\n",
    "    column_name = 'date_dayofweek'\n",
    "    if column_prefix is not None:\n",
    "        column_name = (column_prefix, column_name)        \n",
    "    df[column_name] = df.index.dayofweek\n",
    "    date_columns.append(column_name)\n",
    "\n",
    "    column_name = 'date_hour'\n",
    "    if column_prefix is not None:\n",
    "        column_name = (column_prefix, column_name)        \n",
    "    df[column_name] = df.index.hour\n",
    "    date_columns.append(column_name)\n",
    "    \n",
    "    return df, date_columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "def calc_one_hot_fit_transform(df, column_list):    \n",
    "    one_hot_columns = []\n",
    "    one_hot_encoders = {}\n",
    "\n",
    "    for column_name_original in column_list:\n",
    "        one_hot_encoders[column_name_original] = OneHotEncoder(handle_unknown='ignore')\n",
    "\n",
    "        one_hot_encoders[column_name_original].fit(df[column_name_original].values.reshape(-1, 1))\n",
    "        one_hot_result = one_hot_encoders[column_name_original].transform(df[column_name_original].values.reshape(-1, 1))\n",
    "        \n",
    "        for i in range(one_hot_result.shape[1]):\n",
    "            column_name_one_hot = f'{column_name_original}_{i}'\n",
    "            df[column_name_one_hot] = one_hot_result[:, i].toarray()\n",
    "            \n",
    "            one_hot_columns.append(column_name_one_hot)\n",
    "        \n",
    "    return df, one_hot_columns, one_hot_encoders\n",
    "\n",
    "\n",
    "def calc_one_hot_transform(df, column_list, one_hot_encoders):    \n",
    "    one_hot_columns = []\n",
    "\n",
    "    for column_name_original in column_list:\n",
    "        one_hot_result = one_hot_encoders[column_name_original].transform(df[column_name_original].values.reshape(-1, 1))\n",
    "        \n",
    "        for i in range(one_hot_result.shape[1]):\n",
    "            column_name_one_hot = f'{column_name_original}_{i}'\n",
    "            df[column_name_one_hot] = one_hot_result[:, i].toarray()\n",
    "            \n",
    "            one_hot_columns.append(column_name_one_hot)\n",
    "        \n",
    "    return df, one_hot_columns\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_t_sin_cos(df, k=15, start_t=0, column_prefix=None):\n",
    "    period_list = [1, 7, 12, 24, 24*7, 24*7*4, 365]\n",
    "    \n",
    "    column_t = 't'\n",
    "    if column_prefix is not None:\n",
    "        column_t = (column_prefix, column_t)\n",
    "    \n",
    "    harmonic_columns = [column_t]\n",
    "    \n",
    "    t = np.array(range(start_t, start_t + len(df)))\n",
    "    df[column_t] = t    \n",
    "    \n",
    "    for period in period_list:\n",
    "        for i in range(1, k+1):\n",
    "            column_name = f'sin_{i}_{period}'\n",
    "            if column_prefix is not None:\n",
    "                column_name = (column_prefix, column_name)\n",
    "            harmonic_columns.append(column_name)\n",
    "            df[column_name] = np.sin(df[column_t] * 2 * np.pi * i / period)\n",
    "\n",
    "            column_name = f'cos_{i}_{period}'\n",
    "            if column_prefix is not None:\n",
    "                column_name = (column_prefix, column_name)\n",
    "            harmonic_columns.append(column_name)\n",
    "            df[column_name] = np.cos(df[column_t] * 2 * np.pi * i / period)\n",
    "        \n",
    "    return df, harmonic_columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_lags(df, pivot_regions, K, K_d, N_pred, stat_len, sum_list=[]):\n",
    "    for region_current in tqdm.tqdm(pivot_regions):\n",
    "        columns_lag_plus = []\n",
    "        columns_lag_minus = []\n",
    "        columns_lag_sum = []\n",
    "        columns_lag_stat = []\n",
    "\n",
    "        column_name_count = (region_current, f'count')\n",
    "\n",
    "        for i in range(1, N_pred + 1):\n",
    "            column_name_lag = f'lag_plus_{i}'\n",
    "            column_name_lag_full = (region_current, column_name_lag)\n",
    "            columns_lag_plus.append(column_name_lag)\n",
    "            df_pivot[column_name_lag_full] = df_pivot[column_name_count].shift(-i)\n",
    "\n",
    "        for i in range(1, K + 1):\n",
    "            column_name_lag = f'lag_minus_{i}'\n",
    "            column_name_lag_full = (region_current, column_name_lag)\n",
    "            columns_lag_minus.append(column_name_lag)\n",
    "            df_pivot[column_name_lag_full] = df_pivot[column_name_count].shift(i)\n",
    "\n",
    "        for i in range(1, K_d + 1):\n",
    "            column_name_lag = f'lag_minus_{i * 24}'\n",
    "            column_name_lag_full = (region_current, column_name_lag)\n",
    "            columns_lag_minus.append(column_name_lag)\n",
    "            df_pivot[column_name_lag_full] = df_pivot[column_name_count].shift(i * 24)\n",
    "\n",
    "        for i in sum_list:\n",
    "            column_name_lag = f'lag_sum_{i}'\n",
    "            column_name_lag_full = (region_current, column_name_lag)\n",
    "            columns_lag_sum.append(column_name_lag)\n",
    "            df_pivot[column_name_lag_full] = df_pivot[column_name_count].rolling(i).sum()\n",
    "            df_pivot[column_name_lag_full].fillna(value=df_pivot[column_name_count].cumsum(), inplace=True)\n",
    "\n",
    "        column_name_lag = f'lag_mean_{stat_len}'\n",
    "        column_name_lag_full = (region_current, column_name_lag)\n",
    "        columns_lag_stat.append(column_name_lag)\n",
    "        df_pivot[column_name_lag_full] = df_pivot[column_name_count].rolling(stat_len).mean()\n",
    "        \n",
    "        column_name_lag = f'lag_median_{stat_len}'\n",
    "        column_name_lag_full = (region_current, column_name_lag)\n",
    "        columns_lag_stat.append(column_name_lag)\n",
    "        df_pivot[column_name_lag_full] = df_pivot[column_name_count].rolling(stat_len).median()\n",
    "        \n",
    "        column_name_lag = f'lag_std_{stat_len}'\n",
    "        column_name_lag_full = (region_current, column_name_lag)\n",
    "        columns_lag_stat.append(column_name_lag)\n",
    "        df_pivot[column_name_lag_full] = df_pivot[column_name_count].rolling(stat_len).std()\n",
    "                \n",
    "    return df, columns_lag_plus, columns_lag_minus, columns_lag_sum, columns_lag_stat\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_arima_lags_plus(df, df_arima, lags_count, region_n, column_prefix):\n",
    "    columns_lag_plus = []\n",
    "    \n",
    "    for i in range(1, lags_count + 1):\n",
    "        column_name_lag = f'{column_prefix}_lag_plus_{i}'\n",
    "        column_name_lag_full = (region_n, column_name_lag)\n",
    "        columns_lag_plus.append(column_name_lag)\n",
    "        df[column_name_lag_full] = df_arima.shift(-i)\n",
    "        \n",
    "    return df, columns_lag_plus\n",
    "        \n",
    "        \n",
    "def add_arima(df, df_arima, pivot_regions):\n",
    "    arima_columns = []\n",
    "\n",
    "    new_column_name_linear_sin_cos_predict = 'linear_sin_cos_predict'\n",
    "    new_column_name_sarimax = 'sarimax'\n",
    "    new_column_name_full_predict = 'full_predict'\n",
    "    \n",
    "    arima_columns.append(new_column_name_linear_sin_cos_predict)\n",
    "    arima_columns.append(new_column_name_sarimax)\n",
    "    arima_columns.append(new_column_name_full_predict)\n",
    "\n",
    "    for region_current in tqdm.tqdm(pivot_regions):\n",
    "        old_column_name_linear_sin_cos_predict = f'region_{region_current}_linear_sin_cos_predict'\n",
    "        df[(region_current, new_column_name_linear_sin_cos_predict)] = df_arima[old_column_name_linear_sin_cos_predict]\n",
    "        df, columns_lag_plus = add_arima_lags_plus(df, df_arima[old_column_name_linear_sin_cos_predict], lags_count=N_pred, region_n=region_current, column_prefix=new_column_name_linear_sin_cos_predict)\n",
    "        for column in columns_lag_plus:\n",
    "            if column not in arima_columns:\n",
    "                arima_columns.append(column)\n",
    "\n",
    "        old_column_name_sarimax = f'region_{region_current}_sarimax'\n",
    "        df[(region_current, new_column_name_sarimax)] = df_arima[old_column_name_sarimax]\n",
    "        df, columns_lag_plus = add_arima_lags_plus(df, df_arima[old_column_name_sarimax], lags_count=N_pred, region_n=region_current, column_prefix=new_column_name_sarimax)\n",
    "        for column in columns_lag_plus:\n",
    "            if column not in arima_columns:\n",
    "                arima_columns.append(column)\n",
    "\n",
    "        old_column_name_full_predict = f'region_{region_current}_full_predict'\n",
    "        df[(region_current, new_column_name_full_predict)] = df_arima[old_column_name_full_predict]\n",
    "        df, columns_lag_plus = add_arima_lags_plus(df, df_arima[old_column_name_full_predict], lags_count=N_pred, region_n=region_current, column_prefix=new_column_name_full_predict)\n",
    "        for column in columns_lag_plus:\n",
    "            if column not in arima_columns:\n",
    "                arima_columns.append(column)\n",
    "        \n",
    "    return df, arima_columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_holiday_columns(df, start, end, column_prefix=None):\n",
    "    holiday_columns = []\n",
    "    \n",
    "    calendar = USFederalHolidayCalendar()\n",
    "    holidays = calendar.holidays(start=start, end=end) \n",
    "\n",
    "    column_name = 'holiday'\n",
    "    if column_prefix is not None:\n",
    "        column_name = (column_prefix, column_name)        \n",
    "    df[column_name] = np.isin(df.index.date, holidays.date).astype(int)\n",
    "    holiday_columns.append(column_name)\n",
    "\n",
    "    column_name = 'holiday_minus_1'\n",
    "    if column_prefix is not None:\n",
    "        column_name = (column_prefix, column_name)        \n",
    "    df[column_name] = np.isin(df.index.date, holidays.date - dt.timedelta(days = - 1)).astype(int)\n",
    "    holiday_columns.append(column_name)\n",
    "\n",
    "    column_name = 'holiday_plus_1'\n",
    "    if column_prefix is not None:\n",
    "        column_name = (column_prefix, column_name)        \n",
    "    df[column_name] = np.isin(df.index.date, holidays.date - dt.timedelta(days = + 1)).astype(int)\n",
    "    holiday_columns.append(column_name)\n",
    "\n",
    "    return df, holiday_columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_regions_near(region_n, row_count, col_count):\n",
    "    all_count = row_count * col_count\n",
    "    result = []\n",
    "    \n",
    "    if (region_n + 1) < all_count:\n",
    "        result.append(region_n + 1)\n",
    "        \n",
    "    if (region_n + col_count) < all_count:\n",
    "        result.append(region_n + col_count)\n",
    "\n",
    "    if (region_n + col_count - 1) < all_count:\n",
    "        result.append(region_n + col_count - 1)\n",
    "\n",
    "    if (region_n + col_count + 1) < all_count:\n",
    "        result.append(region_n + col_count + 1)\n",
    "\n",
    "    if (region_n - 1) >= 0:\n",
    "        result.append(region_n - 1)\n",
    "        \n",
    "    if (region_n - col_count) >= 0:\n",
    "        result.append(region_n - col_count)\n",
    "\n",
    "    if (region_n - col_count - 1) >= 0:\n",
    "        result.append(region_n - col_count - 1)\n",
    "\n",
    "    if (region_n - col_count + 1) >= 0:\n",
    "        result.append(region_n - col_count + 1)\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_lags_near(df, pivot_regions, row_count, col_count, near_len, sum_list=[]):\n",
    "    columns_lag_near = []\n",
    "    \n",
    "    for region_current in tqdm.tqdm(pivot_regions):\n",
    "        columns_near = [(region_near, f'count') for region_near in np.unique(get_regions_near(region_current, row_count, col_count))]\n",
    "\n",
    "        for lag_i in range(0, near_len + 1):\n",
    "            for near_i in range(len(columns_near)):\n",
    "                column_name_lag = f'lag_near_{near_i+1}_minus_{lag_i}'\n",
    "                column_name_lag_full = (region_current, column_name_lag)\n",
    "                if column_name_lag not in columns_lag_near:\n",
    "                    columns_lag_near.append(column_name_lag)\n",
    "\n",
    "                df_pivot[column_name_lag_full] = df_pivot[columns_near[near_i]].shift(lag_i)\n",
    "\n",
    "            column_name_lag = f'lag_near_sum_minus_{lag_i}'\n",
    "            column_name_lag_full = (region_current, column_name_lag)\n",
    "            if column_name_lag not in columns_lag_near:\n",
    "                columns_lag_near.append(column_name_lag)\n",
    "\n",
    "            df_pivot[column_name_lag_full] = df_pivot[columns_near].shift(lag_i).sum(axis=1)\n",
    "                \n",
    "        for i in sum_list:\n",
    "            column_name_lag_data = (region_current, f'lag_near_sum_minus_0')\n",
    "\n",
    "            column_name_lag = f'lag_near_sum_sum_{i}'\n",
    "            column_name_lag_full = (region_current, column_name_lag)\n",
    "            if column_name_lag not in columns_lag_near:\n",
    "                columns_lag_near.append(column_name_lag)\n",
    "            df_pivot[column_name_lag_full] = df_pivot[column_name_lag_data].rolling(i).sum()\n",
    "            df_pivot[column_name_lag_full].fillna(value=df_pivot[column_name_lag_data].cumsum(), inplace=True)\n",
    "\n",
    "            column_name_lag = f'lag_near_sum_mean_{i}'\n",
    "            column_name_lag_full = (region_current, column_name_lag)\n",
    "            if column_name_lag not in columns_lag_near:\n",
    "                columns_lag_near.append(column_name_lag)\n",
    "            df_pivot[column_name_lag_full] = df_pivot[column_name_lag_data].rolling(i).mean()\n",
    "\n",
    "            column_name_lag = f'lag_near_sum_median_{i}'\n",
    "            column_name_lag_full = (region_current, column_name_lag)\n",
    "            if column_name_lag not in columns_lag_near:\n",
    "                columns_lag_near.append(column_name_lag)\n",
    "            df_pivot[column_name_lag_full] = df_pivot[column_name_lag_data].rolling(i).median()\n",
    "\n",
    "            column_name_lag = f'lag_near_sum_std_{i}'\n",
    "            column_name_lag_full = (region_current, column_name_lag)\n",
    "            if column_name_lag not in columns_lag_near:\n",
    "                columns_lag_near.append(column_name_lag)\n",
    "            df_pivot[column_name_lag_full] = df_pivot[column_name_lag_data].rolling(i).std()\n",
    "\n",
    "    return df, columns_lag_near\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unpivot_table(df, common_columns, pivot_regions):\n",
    "    result = None\n",
    "\n",
    "\n",
    "    for region_current in tqdm.tqdm(pivot_regions):\n",
    "        df_new = df[common_columns].copy()\n",
    "        \n",
    "        pivot_region_columns = [column for column in df.columns if column[0] == region_current]\n",
    "        unpivot_region_columns = [('region', column[1]) for column in df.columns if column[0] == region_current]\n",
    "        \n",
    "        df_new[('region', 'id')] = region_current\n",
    "        df_new[unpivot_region_columns] = df[pivot_region_columns]\n",
    "        \n",
    "        if result is None:\n",
    "            result = df_new\n",
    "        else:\n",
    "            result = result.append(df_new)\n",
    "            \n",
    "    unpivot_region_columns_dict = {\n",
    "        'id': ('region', 'id'),\n",
    "        'count': ('region', 'count'),               \n",
    "        'lags': [c for c in unpivot_region_columns if c != ('region', 'count')],\n",
    "        'all': [('region', 'id')] + unpivot_region_columns,\n",
    "    }\n",
    "            \n",
    "    return result, common_columns, unpivot_region_columns_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_submission(result):\n",
    "    df = []\n",
    "    for region_n, region_result in result.items():\n",
    "        for history_end, history_result in region_result.items():\n",
    "            submission_date_time = datetime.datetime.strftime(history_end, '%Y-%m-%d_%#H')\n",
    "            for pred_n, pred_value in enumerate(history_result):\n",
    "                df.append([f'{region_n}_{submission_date_time}_{pred_n + 1}', pred_value]) \n",
    "\n",
    "    return pd.DataFrame(df, columns=['id', 'y'])\n",
    "                           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://www.kaggle.com/wittmannf/aula-2-awari\n",
    "\n",
    "## Memory optimization\n",
    "\n",
    "# Original code from https://www.kaggle.com/gemartin/load-data-reduce-memory-usage by @gemartin\n",
    "# Modified to support timestamp type, categorical type\n",
    "# Modified to add option to use float16\n",
    "\n",
    "from pandas.api.types import is_datetime64_any_dtype as is_datetime\n",
    "from pandas.api.types import is_categorical_dtype\n",
    "\n",
    "def reduce_mem_usage(df, use_float16=False):\n",
    "    \"\"\"\n",
    "    Iterate through all the columns of a dataframe and modify the data type to reduce memory usage.        \n",
    "    \"\"\"\n",
    "    \n",
    "    start_mem = df.memory_usage().sum() / 1024**2\n",
    "    print(\"Memory usage of dataframe is {:.2f} MB\".format(start_mem))\n",
    "    \n",
    "    for col in df.columns:\n",
    "        if is_datetime(df[col]) or is_categorical_dtype(df[col]):\n",
    "            continue\n",
    "        col_type = df[col].dtype\n",
    "        \n",
    "        if col_type != object:\n",
    "            c_min = df[col].min()\n",
    "            c_max = df[col].max()\n",
    "            if str(col_type)[:3] == \"int\":\n",
    "                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n",
    "                    df[col] = df[col].astype(np.int8)\n",
    "                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n",
    "                    df[col] = df[col].astype(np.int16)\n",
    "                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n",
    "                    df[col] = df[col].astype(np.int32)\n",
    "                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n",
    "                    df[col] = df[col].astype(np.int64)  \n",
    "            else:\n",
    "                if use_float16 and c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n",
    "                    df[col] = df[col].astype(np.float16)\n",
    "                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n",
    "                    df[col] = df[col].astype(np.float32)\n",
    "                else:\n",
    "                    df[col] = df[col].astype(np.float64)\n",
    "        else:\n",
    "            df[col] = df[col].astype(\"category\")\n",
    "\n",
    "    end_mem = df.memory_usage().sum() / 1024**2\n",
    "    print(\"Memory usage after optimization is: {:.2f} MB\".format(end_mem))\n",
    "    print(\"Decreased by {:.1f}%\".format(100 * (start_mem - end_mem) / start_mem))\n",
    "    \n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from subprocess import check_output\n",
    "# print(check_output([\"ls\", \"../input\"]).decode(\"utf8\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## регионы"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "В следующем файле даны идентификаторы ячеек, которые вам нужно использовать, и географические координаты их границ: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>region</th>\n",
       "      <th>west</th>\n",
       "      <th>east</th>\n",
       "      <th>south</th>\n",
       "      <th>north</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>-74.255590</td>\n",
       "      <td>-74.244478</td>\n",
       "      <td>40.496120</td>\n",
       "      <td>40.504508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>-74.255590</td>\n",
       "      <td>-74.244478</td>\n",
       "      <td>40.504508</td>\n",
       "      <td>40.512896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>-74.255590</td>\n",
       "      <td>-74.244478</td>\n",
       "      <td>40.512896</td>\n",
       "      <td>40.521285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>-74.255590</td>\n",
       "      <td>-74.244478</td>\n",
       "      <td>40.521285</td>\n",
       "      <td>40.529673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>-74.255590</td>\n",
       "      <td>-74.244478</td>\n",
       "      <td>40.529673</td>\n",
       "      <td>40.538061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2495</th>\n",
       "      <td>2496</td>\n",
       "      <td>-73.711122</td>\n",
       "      <td>-73.700010</td>\n",
       "      <td>40.873589</td>\n",
       "      <td>40.881977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2496</th>\n",
       "      <td>2497</td>\n",
       "      <td>-73.711122</td>\n",
       "      <td>-73.700010</td>\n",
       "      <td>40.881977</td>\n",
       "      <td>40.890365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2497</th>\n",
       "      <td>2498</td>\n",
       "      <td>-73.711122</td>\n",
       "      <td>-73.700010</td>\n",
       "      <td>40.890365</td>\n",
       "      <td>40.898754</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2498</th>\n",
       "      <td>2499</td>\n",
       "      <td>-73.711122</td>\n",
       "      <td>-73.700010</td>\n",
       "      <td>40.898754</td>\n",
       "      <td>40.907142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2499</th>\n",
       "      <td>2500</td>\n",
       "      <td>-73.711122</td>\n",
       "      <td>-73.700010</td>\n",
       "      <td>40.907142</td>\n",
       "      <td>40.915530</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2500 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      region       west       east      south      north\n",
       "0          1 -74.255590 -74.244478  40.496120  40.504508\n",
       "1          2 -74.255590 -74.244478  40.504508  40.512896\n",
       "2          3 -74.255590 -74.244478  40.512896  40.521285\n",
       "3          4 -74.255590 -74.244478  40.521285  40.529673\n",
       "4          5 -74.255590 -74.244478  40.529673  40.538061\n",
       "...      ...        ...        ...        ...        ...\n",
       "2495    2496 -73.711122 -73.700010  40.873589  40.881977\n",
       "2496    2497 -73.711122 -73.700010  40.881977  40.890365\n",
       "2497    2498 -73.711122 -73.700010  40.890365  40.898754\n",
       "2498    2499 -73.711122 -73.700010  40.898754  40.907142\n",
       "2499    2500 -73.711122 -73.700010  40.907142  40.915530\n",
       "\n",
       "[2500 rows x 5 columns]"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_regions = pd.read_csv('../input/regions/regions.csv', sep=';')\n",
    "data_regions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_regions['west'].value_counts()\n",
    "# data_regions['east'].value_counts()\n",
    "# data_regions['south'].value_counts()\n",
    "# data_regions['north'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_regions['west'].unique()\n",
    "# data_regions['east'].unique()\n",
    "# data_regions['south'].unique()\n",
    "# data_regions['north'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50, 50, 50, 50)"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data_regions['west'].unique()), len(data_regions['east'].unique()), len(data_regions['south'].unique()), len(data_regions['north'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{-74.25559}"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(data_regions['west'].unique()) - set(data_regions['east'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{40.49612}"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(data_regions['south'].unique()) - set(data_regions['north'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(51, 51)"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_bins = data_regions['west'].append(data_regions['east']).unique()\n",
    "y_bins = data_regions['south'].append(data_regions['north']).unique()\n",
    "\n",
    "len(x_bins), len(y_bins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### найдем ячейки \"которые были отобраны на второй неделе\":\n",
    "* \"отфильтруйте ячейки, из которых в мае совершается в среднем меньше 5 поездок в час. Посчитайте количество оставшихся\"\n",
    "* правильный ответ: 102"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __need_load_more_5:\n",
    "    data_2016_05_more_5 = pd.read_csv(f'../input/data-2016-05-more-5/data_2016_05_more_5.csv')\n",
    "    data_2016_05_more_5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 102 entries, 0 to 101\n",
      "Data columns (total 3 columns):\n",
      " #   Column  Non-Null Count  Dtype  \n",
      "---  ------  --------------  -----  \n",
      " 0   region  102 non-null    int64  \n",
      " 1   month   102 non-null    object \n",
      " 2   count   102 non-null    float64\n",
      "dtypes: float64(1), int64(1), object(1)\n",
      "memory usage: 2.5+ KB\n",
      "None\n",
      "Memory usage of dataframe is 0.00 MB\n",
      "Memory usage after optimization is: 0.00 MB\n",
      "Decreased by 62.8%\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 102 entries, 0 to 101\n",
      "Data columns (total 3 columns):\n",
      " #   Column  Non-Null Count  Dtype   \n",
      "---  ------  --------------  -----   \n",
      " 0   region  102 non-null    int16   \n",
      " 1   month   102 non-null    category\n",
      " 2   count   102 non-null    float32 \n",
      "dtypes: category(1), float32(1), int16(1)\n",
      "memory usage: 958.0 bytes\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(data_2016_05_more_5.info())\n",
    "data_2016_05_more_5 = reduce_mem_usage(data_2016_05_more_5)\n",
    "print(data_2016_05_more_5.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "102"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set(data_2016_05_more_5['region']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      1075\n",
       "1      1076\n",
       "2      1077\n",
       "3      1125\n",
       "4      1126\n",
       "       ... \n",
       "97     2068\n",
       "98     2069\n",
       "99     2118\n",
       "100    2119\n",
       "101    2168\n",
       "Name: region, Length: 102, dtype: int16"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "region_102 = pd.Series(data_2016_05_more_5['region'].unique(), name='region')\n",
    "region_102"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## грузим реальные данные за июнь 2016"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 2.92 s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>region</th>\n",
       "      <th>count</th>\n",
       "      <th>passenger_count</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tpep_pickup_datetime</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2016-06-01 00:00:00</th>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-06-01 00:00:00</th>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-06-01 00:00:00</th>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-06-01 00:00:00</th>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-06-01 00:00:00</th>\n",
       "      <td>5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-06-30 23:00:00</th>\n",
       "      <td>2496</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-06-30 23:00:00</th>\n",
       "      <td>2497</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-06-30 23:00:00</th>\n",
       "      <td>2498</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-06-30 23:00:00</th>\n",
       "      <td>2499</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-06-30 23:00:00</th>\n",
       "      <td>2500</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1800000 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                      region  count  passenger_count\n",
       "tpep_pickup_datetime                                \n",
       "2016-06-01 00:00:00        1    0.0              0.0\n",
       "2016-06-01 00:00:00        2    0.0              0.0\n",
       "2016-06-01 00:00:00        3    0.0              0.0\n",
       "2016-06-01 00:00:00        4    0.0              0.0\n",
       "2016-06-01 00:00:00        5    0.0              0.0\n",
       "...                      ...    ...              ...\n",
       "2016-06-30 23:00:00     2496    0.0              0.0\n",
       "2016-06-30 23:00:00     2497    0.0              0.0\n",
       "2016-06-30 23:00:00     2498    0.0              0.0\n",
       "2016-06-30 23:00:00     2499    0.0              0.0\n",
       "2016-06-30 23:00:00     2500    0.0              0.0\n",
       "\n",
       "[1800000 rows x 3 columns]"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "test_period = '2016-06'\n",
    "dates = [(2016, 6)]\n",
    "\n",
    "if __need_pipeline_2016_06:\n",
    "    data_2016_06 = full_pipeline(get_names(use_local=True, dates=dates),\n",
    "                              nrows=__nrows_pipeline,\n",
    "                              bins=[x_bins, y_bins],\n",
    "                              data_regions=data_regions\n",
    "                             )\n",
    "    data_2016_06.to_csv(f'../input/test-period/data_{test_period}.csv', index=False)\n",
    "else:\n",
    "    data_2016_06 = pd.read_csv(f'../input/test-period/data_{test_period}.csv', parse_dates=['tpep_pickup_datetime'])\n",
    "    \n",
    "data_2016_06.set_index('tpep_pickup_datetime', inplace=True)\n",
    "\n",
    "data_2016_06\n",
    "\n",
    "# Wall time: 2min 5s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2500, array([   1,    2,    3, ..., 2498, 2499, 2500], dtype=int64))"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data_2016_06['region'].unique()), data_2016_06['region'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## грузим сохраненные прогнозы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>region</th>\n",
       "      <th>prediction_1</th>\n",
       "      <th>prediction_2</th>\n",
       "      <th>prediction_3</th>\n",
       "      <th>prediction_4</th>\n",
       "      <th>prediction_5</th>\n",
       "      <th>prediction_6</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tpep_pickup_datetime</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2016-05-31 23:00:00</th>\n",
       "      <td>1075</td>\n",
       "      <td>17.619010</td>\n",
       "      <td>8.224202</td>\n",
       "      <td>2.018704</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.903345</td>\n",
       "      <td>8.393534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-06-01 00:00:00</th>\n",
       "      <td>1075</td>\n",
       "      <td>9.673828</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.033983</td>\n",
       "      <td>19.910736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-06-01 01:00:00</th>\n",
       "      <td>1075</td>\n",
       "      <td>4.171190</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.490225</td>\n",
       "      <td>6.892937</td>\n",
       "      <td>17.122822</td>\n",
       "      <td>41.362362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-06-01 02:00:00</th>\n",
       "      <td>1075</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.737076</td>\n",
       "      <td>7.687000</td>\n",
       "      <td>17.118067</td>\n",
       "      <td>46.756940</td>\n",
       "      <td>65.408770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-06-01 03:00:00</th>\n",
       "      <td>1075</td>\n",
       "      <td>2.934197</td>\n",
       "      <td>7.270452</td>\n",
       "      <td>16.897337</td>\n",
       "      <td>45.893880</td>\n",
       "      <td>72.004260</td>\n",
       "      <td>56.914963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-06-30 13:00:00</th>\n",
       "      <td>2168</td>\n",
       "      <td>34.329224</td>\n",
       "      <td>72.508090</td>\n",
       "      <td>64.300920</td>\n",
       "      <td>57.213905</td>\n",
       "      <td>64.762170</td>\n",
       "      <td>67.217230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-06-30 14:00:00</th>\n",
       "      <td>2168</td>\n",
       "      <td>62.413643</td>\n",
       "      <td>64.606300</td>\n",
       "      <td>61.565964</td>\n",
       "      <td>69.959040</td>\n",
       "      <td>85.483345</td>\n",
       "      <td>82.319150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-06-30 15:00:00</th>\n",
       "      <td>2168</td>\n",
       "      <td>36.587746</td>\n",
       "      <td>52.555923</td>\n",
       "      <td>67.595420</td>\n",
       "      <td>85.119090</td>\n",
       "      <td>99.037000</td>\n",
       "      <td>88.867810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-06-30 16:00:00</th>\n",
       "      <td>2168</td>\n",
       "      <td>38.274883</td>\n",
       "      <td>63.500320</td>\n",
       "      <td>83.461330</td>\n",
       "      <td>98.109040</td>\n",
       "      <td>100.099160</td>\n",
       "      <td>86.239136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-06-30 17:00:00</th>\n",
       "      <td>2168</td>\n",
       "      <td>52.018490</td>\n",
       "      <td>82.964250</td>\n",
       "      <td>102.034676</td>\n",
       "      <td>106.509330</td>\n",
       "      <td>92.202400</td>\n",
       "      <td>67.121380</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>72930 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                      region  prediction_1  prediction_2  prediction_3  \\\n",
       "tpep_pickup_datetime                                                     \n",
       "2016-05-31 23:00:00     1075     17.619010      8.224202      2.018704   \n",
       "2016-06-01 00:00:00     1075      9.673828      0.000000      0.000000   \n",
       "2016-06-01 01:00:00     1075      4.171190      0.000000      2.490225   \n",
       "2016-06-01 02:00:00     1075      0.000000      2.737076      7.687000   \n",
       "2016-06-01 03:00:00     1075      2.934197      7.270452     16.897337   \n",
       "...                      ...           ...           ...           ...   \n",
       "2016-06-30 13:00:00     2168     34.329224     72.508090     64.300920   \n",
       "2016-06-30 14:00:00     2168     62.413643     64.606300     61.565964   \n",
       "2016-06-30 15:00:00     2168     36.587746     52.555923     67.595420   \n",
       "2016-06-30 16:00:00     2168     38.274883     63.500320     83.461330   \n",
       "2016-06-30 17:00:00     2168     52.018490     82.964250    102.034676   \n",
       "\n",
       "                      prediction_4  prediction_5  prediction_6  \n",
       "tpep_pickup_datetime                                            \n",
       "2016-05-31 23:00:00       0.000000      2.903345      8.393534  \n",
       "2016-06-01 00:00:00       0.000000      4.033983     19.910736  \n",
       "2016-06-01 01:00:00       6.892937     17.122822     41.362362  \n",
       "2016-06-01 02:00:00      17.118067     46.756940     65.408770  \n",
       "2016-06-01 03:00:00      45.893880     72.004260     56.914963  \n",
       "...                            ...           ...           ...  \n",
       "2016-06-30 13:00:00      57.213905     64.762170     67.217230  \n",
       "2016-06-30 14:00:00      69.959040     85.483345     82.319150  \n",
       "2016-06-30 15:00:00      85.119090     99.037000     88.867810  \n",
       "2016-06-30 16:00:00      98.109040    100.099160     86.239136  \n",
       "2016-06-30 17:00:00     106.509330     92.202400     67.121380  \n",
       "\n",
       "[72930 rows x 7 columns]"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_val_result_06_save = pd.read_csv('../input/result/df_val_result_06_save.csv',\n",
    "                               parse_dates=['tpep_pickup_datetime'],\n",
    "                              )\n",
    "df_val_result_06_save.set_index('tpep_pickup_datetime', inplace=True)\n",
    "\n",
    "df_val_result_06_save\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### выравниваем длину рельных и прогнозных данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>region</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tpep_pickup_datetime</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2016-06-01 00:00:00</th>\n",
       "      <td>1075</td>\n",
       "      <td>26.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-06-01 00:00:00</th>\n",
       "      <td>1076</td>\n",
       "      <td>30.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-06-01 00:00:00</th>\n",
       "      <td>1077</td>\n",
       "      <td>19.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-06-01 00:00:00</th>\n",
       "      <td>1125</td>\n",
       "      <td>39.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-06-01 00:00:00</th>\n",
       "      <td>1126</td>\n",
       "      <td>71.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-06-30 17:00:00</th>\n",
       "      <td>2068</td>\n",
       "      <td>189.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-06-30 17:00:00</th>\n",
       "      <td>2069</td>\n",
       "      <td>15.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-06-30 17:00:00</th>\n",
       "      <td>2118</td>\n",
       "      <td>210.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-06-30 17:00:00</th>\n",
       "      <td>2119</td>\n",
       "      <td>129.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-06-30 17:00:00</th>\n",
       "      <td>2168</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>72828 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                      region  count\n",
       "tpep_pickup_datetime               \n",
       "2016-06-01 00:00:00     1075   26.0\n",
       "2016-06-01 00:00:00     1076   30.0\n",
       "2016-06-01 00:00:00     1077   19.0\n",
       "2016-06-01 00:00:00     1125   39.0\n",
       "2016-06-01 00:00:00     1126   71.0\n",
       "...                      ...    ...\n",
       "2016-06-30 17:00:00     2068  189.0\n",
       "2016-06-30 17:00:00     2069   15.0\n",
       "2016-06-30 17:00:00     2118  210.0\n",
       "2016-06-30 17:00:00     2119  129.0\n",
       "2016-06-30 17:00:00     2168    1.0\n",
       "\n",
       "[72828 rows x 2 columns]"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_real_2016_06 = data_2016_06\n",
    "\n",
    "df_real_2016_06 = df_real_2016_06[df_real_2016_06['region'].isin(region_102)][['region', 'count']]\n",
    "df_real_2016_06 = df_real_2016_06[df_real_2016_06.index <= '2016-06-30 17:00:00']\n",
    "\n",
    "df_real_2016_06"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>region</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tpep_pickup_datetime</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2016-06-01 00:00:00</th>\n",
       "      <td>1075</td>\n",
       "      <td>9.673828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-06-01 01:00:00</th>\n",
       "      <td>1075</td>\n",
       "      <td>4.171190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-06-01 02:00:00</th>\n",
       "      <td>1075</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-06-01 03:00:00</th>\n",
       "      <td>1075</td>\n",
       "      <td>2.934197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-06-01 04:00:00</th>\n",
       "      <td>1075</td>\n",
       "      <td>6.061596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-06-30 13:00:00</th>\n",
       "      <td>2168</td>\n",
       "      <td>34.329224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-06-30 14:00:00</th>\n",
       "      <td>2168</td>\n",
       "      <td>62.413643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-06-30 15:00:00</th>\n",
       "      <td>2168</td>\n",
       "      <td>36.587746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-06-30 16:00:00</th>\n",
       "      <td>2168</td>\n",
       "      <td>38.274883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-06-30 17:00:00</th>\n",
       "      <td>2168</td>\n",
       "      <td>52.018490</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>72828 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                      region      count\n",
       "tpep_pickup_datetime                   \n",
       "2016-06-01 00:00:00     1075   9.673828\n",
       "2016-06-01 01:00:00     1075   4.171190\n",
       "2016-06-01 02:00:00     1075   0.000000\n",
       "2016-06-01 03:00:00     1075   2.934197\n",
       "2016-06-01 04:00:00     1075   6.061596\n",
       "...                      ...        ...\n",
       "2016-06-30 13:00:00     2168  34.329224\n",
       "2016-06-30 14:00:00     2168  62.413643\n",
       "2016-06-30 15:00:00     2168  36.587746\n",
       "2016-06-30 16:00:00     2168  38.274883\n",
       "2016-06-30 17:00:00     2168  52.018490\n",
       "\n",
       "[72828 rows x 2 columns]"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pred_2016_06 = df_val_result_06_save[df_val_result_06_save.index >= '2016-06-01 00:00:00'][['region', 'prediction_1']].copy()\n",
    "df_pred_2016_06.columns = ['region', 'count']\n",
    "df_pred_2016_06\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(72828, 72828)"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_real_2016_06), len(df_pred_2016_06)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory usage of dataframe is 1.67 MB\n",
      "Memory usage after optimization is: 0.97 MB\n",
      "Decreased by 41.7%\n"
     ]
    }
   ],
   "source": [
    "df_real_2016_06 = reduce_mem_usage(df_real_2016_06)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory usage of dataframe is 1.67 MB\n",
      "Memory usage after optimization is: 0.97 MB\n",
      "Decreased by 41.7%\n"
     ]
    }
   ],
   "source": [
    "df_pred_2016_06 = reduce_mem_usage(df_pred_2016_06)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# карты с визуализацией реального и прогнозируемого спроса на такси в выбираемый пользователем момент времени"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_polygons(data_regions):\n",
    "    result = []\n",
    "\n",
    "    for n_region in region_102:\n",
    "        region_i = data_regions[data_regions['region'] == n_region]\n",
    "\n",
    "        result.append(\n",
    "            [\n",
    "                (region_i['north'].values[0], region_i['west'].values[0]), \n",
    "                (region_i['north'].values[0], region_i['east'].values[0]), \n",
    "                (region_i['south'].values[0], region_i['east'].values[0]), \n",
    "                (region_i['south'].values[0], region_i['west'].values[0]), \n",
    "                (region_i['north'].values[0], region_i['west'].values[0]), \n",
    "            ],\n",
    "        )\n",
    "    \n",
    "    return result\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[(40.705825, -74.0222464),\n",
       "  (40.705825, -74.0111348),\n",
       "  (40.6974368, -74.0111348),\n",
       "  (40.6974368, -74.0222464),\n",
       "  (40.705825, -74.0222464)],\n",
       " [(40.7142132, -74.0222464),\n",
       "  (40.7142132, -74.0111348),\n",
       "  (40.705825, -74.0111348),\n",
       "  (40.705825, -74.0222464),\n",
       "  (40.7142132, -74.0222464)],\n",
       " [(40.7226014, -74.0222464),\n",
       "  (40.7226014, -74.0111348),\n",
       "  (40.7142132, -74.0111348),\n",
       "  (40.7142132, -74.0222464),\n",
       "  (40.7226014, -74.0222464)],\n",
       " [(40.705825, -74.0111348),\n",
       "  (40.705825, -74.0000232),\n",
       "  (40.6974368, -74.0000232),\n",
       "  (40.6974368, -74.0111348),\n",
       "  (40.705825, -74.0111348)],\n",
       " [(40.7142132, -74.0111348),\n",
       "  (40.7142132, -74.0000232),\n",
       "  (40.705825, -74.0000232),\n",
       "  (40.705825, -74.0111348),\n",
       "  (40.7142132, -74.0111348)]]"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "polygon_regions_all = calc_polygons(data_regions)    \n",
    "polygon_regions_all[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_data(data_source, date_time):\n",
    "    result = []\n",
    "\n",
    "    for index_current, row_current in data_source[data_source.index == date_time].iterrows():\n",
    "        n_region = row_current['region']\n",
    "        c_region = row_current['count']\n",
    "\n",
    "        region_i = data_regions[data_regions['region'] == n_region]\n",
    "        x_region = (region_i['west'] + region_i['east']) / 2\n",
    "        y_region = (region_i['south'] + region_i['north']) / 2\n",
    "\n",
    "        result.append([y_region.values[0], x_region.values[0], c_region])\n",
    "        \n",
    "    return np.array(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_map(data, polygon_regions_all):\n",
    "    map_object = folium.Map(location=[(new_york_coords['south'] + new_york_coords['north']) / 2, (new_york_coords['west'] + new_york_coords['east']) / 2], zoom_start=11)\n",
    "\n",
    "    HeatMap(data[:, 0:3]).add_to(map_object)\n",
    "\n",
    "    for polugon_i, polygon_region in enumerate(polygon_regions_all):\n",
    "        folium.PolyLine(polygon_region, color='black', weight=0.2).add_to(map_object)\n",
    "\n",
    "    return map_object\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_map(date_time, df_real, df_pred, polygon_regions_all):\n",
    "    data_real = calc_data(data_source=df_real, date_time=date_time)\n",
    "    map_object_real = calc_map(data_real, polygon_regions_all)\n",
    "    display(map_object_real)\n",
    "\n",
    "    data_pred = calc_data(data_source=df_pred, date_time=date_time)\n",
    "    map_object_pred = calc_map(data_pred, polygon_regions_all)\n",
    "    display(map_object_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "# date_time = '2016-06-30 00:00:00'\n",
    "# show_map(date_time=date_time, df_real=df_real_2016_06, df_pred=df_pred_2016_06, polygon_regions_all=polygon_regions_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_map(date_time):\n",
    "    show_map(date_time, df_real=df_real_2016_06, df_pred=df_pred_2016_06, polygon_regions_all=polygon_regions_all)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Layout' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-103-084803f80748>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mdate_time_values\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf_real_2016_06\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0minteractive\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mupdate_map\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdate_time\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mwidgets\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSelectionSlider\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moptions\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdate_time_values\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlayout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mLayout\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwidth\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'85%'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mheight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'80px'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'Layout' is not defined"
     ]
    }
   ],
   "source": [
    "date_time_values = df_real_2016_06.index\n",
    "interactive(update_map, date_time = widgets.SelectionSlider(options = date_time_values, layout=Layout(width='85%', height='80px')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# временной ряд фактического и прогнозируемого спроса на такси в выбираемой области."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_plot(region_n):\n",
    "    fig, ax = subplots(1, 1, figsize=(19, 9))\n",
    "\n",
    "    ax.set_title(f'region={region_n}')\n",
    "\n",
    "    ax.plot(df_real_2016_06[df_real_2016_06['region'] == region_n]['count'], label='real')\n",
    "    ax.plot(df_pred_2016_06[df_pred_2016_06['region'] == region_n]['count'], label='pred')\n",
    "    \n",
    "    ax.legend()\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show_plot(region_n=1075)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ipywidgets import *\n",
    "\n",
    "def f(x):\n",
    "    show_plot(region_n=x)\n",
    "    \n",
    "widgets.interact(f, x=region_102)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
